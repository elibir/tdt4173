{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Long notebook"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ts(y: pd.DataFrame, x:pd.DataFrame, start, end, feature, shareX: bool):\n",
    "    \"\"\"\n",
    "    Plots all the y arrays, then all the x arrays.\n",
    "    \"\"\"\n",
    "    fig, axs = plt.subplots(len(x)+len(y), 1, figsize=(15,10), sharex=shareX)\n",
    "    i = 0\n",
    "    for df in y:\n",
    "        df[(df.index >= start) & (df.index <= end)].resample(\"H\").mean().plot(ax=axs[i])\n",
    "        i += 1\n",
    "    \n",
    "    for df in x:\n",
    "        df[(df.index >= start) & (df.index <= end)].resample(\"H\").mean()[feature].plot(ax=axs[i], label=feature, color=\"red\")\n",
    "        axs[i].legend()\n",
    "        i += 1\n",
    "    \n",
    "            \n",
    "def plot_ts1(y: pd.DataFrame, x:pd.DataFrame, start, end, feature, shareX: bool):\n",
    "    \"\"\"\n",
    "    Plots the y and x values directly under each other for each location\n",
    "    \"\"\"\n",
    "    \n",
    "    if len(x) != len(y):\n",
    "        print(\"Error: arrays 'y' and 'x' are different lengths. Please provide equal sized arrays.\")\n",
    "    else:\n",
    "        fig, axs = plt.subplots(len(x)+len(y), 1, figsize=(15,10), sharex=shareX)\n",
    "        i = 0\n",
    "        for df_y, df_x in zip(y, x):\n",
    "                df_y[(df_y.index >= start) & (df_y.index <= end)].resample(\"H\").mean().plot(ax=axs[i])\n",
    "                i += 1\n",
    "                df_x[(df_x.index >= start) & (df_x.index <= end)].resample(\"H\").mean()[feature].plot(ax=axs[i], label=feature, color=\"red\")\n",
    "                axs[i].legend()\n",
    "                i += 1\n",
    "  \n",
    "\n",
    "def remove_constant_values(df, column_name, threshold):\n",
    "    \n",
    "    new_df = df.copy()\n",
    "\n",
    "    # Find the consecutive constant rows\n",
    "    consecutive_constants = new_df.groupby((new_df[column_name] != new_df[column_name].shift()).cumsum()).filter(lambda x: len(x) > threshold)\n",
    "\n",
    "    # Filter out the consecutive constant rows from the original DataFrame\n",
    "    filtered_df = new_df[~new_df.index.isin(consecutive_constants.index)]\n",
    "    \n",
    "    return filtered_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check If The Data is Intuitive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We assume that the data subfolder is located in the same folder as this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_a = pd.read_parquet('data/A/train_targets.parquet')\n",
    "targets_b = pd.read_parquet('data/B/train_targets.parquet')\n",
    "targets_c = pd.read_parquet('data/C/train_targets.parquet')\n",
    "targets_a = targets_a.set_index('time')\n",
    "targets_b = targets_b.set_index(\"time\")\n",
    "targets_c = targets_c.set_index(\"time\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_observed_a = pd.read_parquet('data/A/X_train_observed.parquet')\n",
    "X_train_observed_b = pd.read_parquet('data/B/X_train_observed.parquet')\n",
    "X_train_observed_c = pd.read_parquet('data/C/X_train_observed.parquet')\n",
    "X_train_observed_a = X_train_observed_a.set_index(\"date_forecast\")\n",
    "X_train_observed_b = X_train_observed_b.set_index(\"date_forecast\")\n",
    "X_train_observed_c = X_train_observed_c.set_index(\"date_forecast\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_estimated_a = pd.read_parquet('data/A/X_train_estimated.parquet')\n",
    "X_train_estimated_b = pd.read_parquet('data/B/X_train_estimated.parquet')\n",
    "X_train_estimated_c = pd.read_parquet('data/C/X_train_estimated.parquet')\n",
    "X_train_estimated_a = X_train_estimated_a.set_index(\"date_forecast\")\n",
    "X_train_estimated_b = X_train_estimated_b.set_index(\"date_forecast\")\n",
    "X_train_estimated_c = X_train_estimated_c.set_index(\"date_forecast\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_estimated_a = pd.read_parquet('data/A/X_test_estimated.parquet')\n",
    "X_test_estimated_b = pd.read_parquet('data/B/X_test_estimated.parquet')\n",
    "X_test_estimated_c = pd.read_parquet('data/C/X_test_estimated.parquet')\n",
    "X_test_estimated_a = X_test_estimated_a.set_index(\"date_forecast\")\n",
    "X_test_estimated_b = X_test_estimated_b.set_index(\"date_forecast\")\n",
    "X_test_estimated_c = X_test_estimated_c.set_index(\"date_forecast\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When plotting the data we noticed that there are constant pv_measurements that are not 0, which seems faulty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### generalized plotting\n",
    "start_date = '2019'\n",
    "end_date = '2024'\n",
    "\n",
    "feature_name = \"direct_rad:W\"\n",
    "\n",
    "Y = [targets_a, targets_b, targets_c,]\n",
    "X = [X_train_observed_a, X_train_observed_b, X_train_observed_c,]\n",
    "\n",
    "plot_ts1(y=Y, \n",
    "              x=X, \n",
    "              feature=feature_name, \n",
    "              start=start_date, \n",
    "              end=end_date, \n",
    "              shareX=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a function to remove these values, and see the changes from the plot. We set the threshold to 18 hours, as that is roughly the length of the longest night of the year (we do not want to remove the nightime where pv_measurement should be 0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing rows where pv_measurment remains the same for more than 18 hours.\n",
    "targets_a = remove_constant_values(targets_a, \"pv_measurement\", 18).dropna()\n",
    "targets_b = remove_constant_values(targets_b, \"pv_measurement\", 18).dropna()\n",
    "targets_c = remove_constant_values(targets_c, \"pv_measurement\", 18).dropna()\n",
    "\n",
    "Y = [targets_a, targets_b, targets_c]\n",
    "X = [X_train_observed_a, X_train_observed_b, X_train_observed_c, ]\n",
    "\n",
    "start_date = '2019'\n",
    "end_date = '2024'\n",
    "feature_name = \"direct_rad:W\"\n",
    "\n",
    "plot_ts1(y=Y, \n",
    "              x=X, \n",
    "              feature=feature_name, \n",
    "              start=start_date, \n",
    "              end=end_date, \n",
    "              shareX=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Up Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We checked if some features had missing values. For example in all of our attempts with the AutoGluon model, we remove the snow_density column. Although not printed here, we have checked the train_estimated and test_estimated datasets as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train_observed_a.shape[0])\n",
    "print(X_train_observed_a.columns.shape[0])\n",
    "X_train_observed_a.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train_observed_b.shape[0])\n",
    "print(X_train_observed_b.columns.shape[0])\n",
    "X_train_observed_b.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train_observed_c.shape[0])\n",
    "print(X_train_observed_c.columns.shape[0])\n",
    "X_train_observed_c.isna().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictors:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of our earlier attempts utilized the XGBoost algorithm. The preprocessing we did was removing targets (pv_measurement), where the value remained constant for over 18 hours. We assumed this to be an error in the measurements. As the targets variables are on an hourly interval and the weather features are each quarter hour - we simply merged the X and y dataframes on every whole hour. For feature engineering we created some time based features such as hour, dayofyear, month etc. We tried running the model with different validation data and removing various features based on low importance. Ultimately the best result we got with this model was 154.768849 on Kaggle. This version simply used all the 45 weather features on each location. And only trained on actual observed weather. Regarding model interpretation we looked at the feature importances for each location, in addition to using the X_train_estimated weather as a local test set. We looked at the plots for the model predictions vs the plots of the actual pv_measurements. We also printed the largest errors the model made to try to interpret what went wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in files and indexing them on time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_a = pd.read_parquet('data/A/train_targets.parquet')\n",
    "targets_b = pd.read_parquet('data/B/train_targets.parquet')\n",
    "targets_c = pd.read_parquet('data/C/train_targets.parquet')\n",
    "targets_a = targets_a.set_index('time')\n",
    "targets_b = targets_b.set_index(\"time\")\n",
    "targets_c = targets_c.set_index(\"time\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_observed_a = pd.read_parquet('data/A/X_train_observed.parquet')\n",
    "X_train_observed_b = pd.read_parquet('data/B/X_train_observed.parquet')\n",
    "X_train_observed_c = pd.read_parquet('data/C/X_train_observed.parquet')\n",
    "X_train_observed_a = X_train_observed_a.set_index(\"date_forecast\")\n",
    "X_train_observed_b = X_train_observed_b.set_index(\"date_forecast\")\n",
    "X_train_observed_c = X_train_observed_c.set_index(\"date_forecast\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_estimated_a = pd.read_parquet('data/A/X_train_estimated.parquet')\n",
    "X_train_estimated_b = pd.read_parquet('data/B/X_train_estimated.parquet')\n",
    "X_train_estimated_c = pd.read_parquet('data/C/X_train_estimated.parquet')\n",
    "X_train_estimated_a = X_train_estimated_a.set_index(\"date_forecast\")\n",
    "X_train_estimated_b = X_train_estimated_b.set_index(\"date_forecast\")\n",
    "X_train_estimated_c = X_train_estimated_c.set_index(\"date_forecast\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_estimated_a = pd.read_parquet('data/A/X_test_estimated.parquet')\n",
    "X_test_estimated_b = pd.read_parquet('data/B/X_test_estimated.parquet')\n",
    "X_test_estimated_c = pd.read_parquet('data/C/X_test_estimated.parquet')\n",
    "X_test_estimated_a = X_test_estimated_a.set_index(\"date_forecast\")\n",
    "X_test_estimated_b = X_test_estimated_b.set_index(\"date_forecast\")\n",
    "X_test_estimated_c = X_test_estimated_c.set_index(\"date_forecast\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ts(y: pd.DataFrame, x:pd.DataFrame, start, end, feature, shareX: bool):\n",
    "    \"\"\"\n",
    "    Plots all the y arrays, then all the x arrays.\n",
    "    \"\"\"\n",
    "    fig, axs = plt.subplots(len(x)+len(y), 1, figsize=(15,10), sharex=shareX)\n",
    "    i = 0\n",
    "    for df in y:\n",
    "        df[(df.index >= start) & (df.index <= end)].resample(\"H\").mean().plot(ax=axs[i])\n",
    "        i += 1\n",
    "    \n",
    "    for df in x:\n",
    "        df[(df.index >= start) & (df.index <= end)].resample(\"H\").mean()[feature].plot(ax=axs[i], label=feature, color=\"red\")\n",
    "        axs[i].legend()\n",
    "        i += 1\n",
    "    \n",
    "            \n",
    "def plot_ts1(y: pd.DataFrame, x:pd.DataFrame, start, end, feature, shareX: bool):\n",
    "    \"\"\"\n",
    "    Plots the y and x values directly under each other for each location\n",
    "    \"\"\"\n",
    "    \n",
    "    if len(x) != len(y):\n",
    "        print(\"Error: arrays 'y' and 'x' are different lengths. Please provide equal sized arrays.\")\n",
    "    else:\n",
    "        fig, axs = plt.subplots(len(x)+len(y), 1, figsize=(15,10), sharex=shareX)\n",
    "        i = 0\n",
    "        for df_y, df_x in zip(y, x):\n",
    "                df_y[(df_y.index >= start) & (df_y.index <= end)].resample(\"H\").mean().plot(ax=axs[i])\n",
    "                i += 1\n",
    "                df_x[(df_x.index >= start) & (df_x.index <= end)].resample(\"H\").mean()[feature].plot(ax=axs[i], label=feature, color=\"red\")\n",
    "                axs[i].legend()\n",
    "                i += 1\n",
    "  \n",
    "\n",
    "def remove_constant_values(df, column_name, threshold):\n",
    "    \n",
    "    new_df = df.copy()\n",
    "\n",
    "    # Find the consecutive constant rows\n",
    "    consecutive_constants = new_df.groupby((new_df[column_name] != new_df[column_name].shift()).cumsum()).filter(lambda x: len(x) > threshold)\n",
    "\n",
    "    # Filter out the consecutive constant rows from the original DataFrame\n",
    "    filtered_df = new_df[~new_df.index.isin(consecutive_constants.index)]\n",
    "    \n",
    "    return filtered_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Specific EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice that missing rows are simply non-existent for Y_train_a, not filled with NaN or anything\n",
    "# From 21. october\n",
    "display(targets_a[29660:29670])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### generalized plotting\n",
    "start_date = '2019'\n",
    "end_date = '2024'\n",
    "\n",
    "feature_name = \"direct_rad:W\"\n",
    "\n",
    "Y = [targets_a, targets_b, targets_c,]\n",
    "X = [X_train_observed_a, X_train_observed_b, X_train_observed_c,]\n",
    "\n",
    "plot_ts1(y=Y, \n",
    "              x=X, \n",
    "              feature=feature_name, \n",
    "              start=start_date, \n",
    "              end=end_date, \n",
    "              shareX=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing and Feature Engineering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing rows where pv_measurment remains the same for more than 18 hours.\n",
    "targets_a = remove_constant_values(targets_a, \"pv_measurement\", 18).dropna()\n",
    "targets_b = remove_constant_values(targets_b, \"pv_measurement\", 18).dropna()\n",
    "targets_c = remove_constant_values(targets_c, \"pv_measurement\", 18).dropna()\n",
    "\n",
    "Y = [targets_a, targets_b, targets_c]\n",
    "X = [X_train_observed_a, X_train_observed_b, X_train_observed_c, ]\n",
    "\n",
    "start_date = '2019'\n",
    "end_date = '2024'\n",
    "feature_name = \"direct_rad:W\"\n",
    "\n",
    "plot_ts1(y=Y, \n",
    "              x=X, \n",
    "              feature=feature_name, \n",
    "              start=start_date, \n",
    "              end=end_date, \n",
    "              shareX=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(df):\n",
    "    new_df = df.copy()\n",
    "    new_df['hour'] = new_df.index.hour\n",
    "    new_df['dayofweek'] = new_df.index.dayofweek\n",
    "    new_df['quarter'] = new_df.index.quarter\n",
    "    new_df['month'] = new_df.index.month\n",
    "    new_df['year'] = new_df.index.year\n",
    "    new_df['dayofyear'] = new_df.index.dayofyear\n",
    "    new_df['dayofmonth'] = new_df.index.day\n",
    "    new_df['weekofyear'] = new_df.index.isocalendar().week\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Adding more time based features to the datasets\n",
    "X_train_observed_a = create_features(X_train_observed_a)\n",
    "X_train_observed_b = create_features(X_train_observed_b)\n",
    "X_train_observed_c = create_features(X_train_observed_c)\n",
    "\n",
    "X_train_estimated_a = create_features(X_train_estimated_a)\n",
    "X_train_estimated_b = create_features(X_train_estimated_b)\n",
    "X_train_estimated_c = create_features(X_train_estimated_c)\n",
    "\n",
    "X_test_estimated_a = create_features(X_test_estimated_a)\n",
    "X_test_estimated_b = create_features(X_test_estimated_b)\n",
    "X_test_estimated_c = create_features(X_test_estimated_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Using only observed weather for training\n",
    "# Join the y values into x-dataframes for training\n",
    "train_a = pd.merge(X_train_observed_a, targets_a, left_index=True, right_index=True)\n",
    "train_b = pd.merge(X_train_observed_b, targets_b, left_index=True, right_index=True)\n",
    "train_c = pd.merge(X_train_observed_c, targets_c, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check which features most correlated with y\n",
    "# correlations = train_a.corrwith(train_a[\"pv_measurement\"])\n",
    "# for index, corr in correlations.items():\n",
    "#     correlations[index] = abs(corr)\n",
    "\n",
    "# sorted = correlations.sort_values(ascending=False)\n",
    "# best_features = list(sorted[1:10].index)\n",
    "# print(best_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating The Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Create the full list of features\n",
    "FEATURES = list(train_a.columns[:-1])  # Using all the features of X.\n",
    "TARGETS = \"pv_measurement\"\n",
    "\n",
    "### DATA\n",
    "X_a = train_a[FEATURES]\n",
    "y_a = train_a[TARGETS]\n",
    "\n",
    "X_b = train_b[FEATURES]\n",
    "y_b = train_b[TARGETS]\n",
    "\n",
    "X_c = train_c[FEATURES]\n",
    "y_c = train_c[TARGETS]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Define the hyperparameters and their possible values\n",
    "param_dist = {\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.3],\n",
    "    'max_depth': [3, 4, 5, 6, 7, 8, 10],\n",
    "    'subsample': [0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    'n_estimators': [100, 200, 500, 1000],\n",
    "    'gamma': [0, 0.25, 0.5, 1.0],\n",
    "    'min_child_weight': [1, 2, 3, 4]\n",
    "}\n",
    "\n",
    "# Initialize XGBRegressor\n",
    "reg = xgb.XGBRegressor()\n",
    "\n",
    "# Initialize RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    reg, \n",
    "    param_distributions=param_dist, \n",
    "    n_iter=100, \n",
    "    scoring='neg_mean_absolute_error', \n",
    "    verbose=1, \n",
    "    cv=3, \n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "# random_search.fit(X_train_a, y_train_a)\n",
    "# random_search.fit(X_train_b, y_train_b)\n",
    "# random_search.fit(X_train_c, y_train_c)\n",
    "\n",
    "# Print the best parameters\n",
    "# print(random_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_params = {\n",
    "    'n_estimators': 1000,\n",
    "    'learning_rate': 0.01,\n",
    "    'early_stopping_rounds': 100,\n",
    "    'objective': 'reg:absoluteerror'\n",
    "}\n",
    "\n",
    "best_params_a = {'subsample': 0.9, \n",
    "               'n_estimators': 1000, \n",
    "               'min_child_weight': 3, \n",
    "               'max_depth': 8, \n",
    "               'learning_rate': 0.05, \n",
    "               'gamma': 0.25, \n",
    "               'colsample_bytree': 0.5,\n",
    "               'objective': 'reg:absoluteerror',\n",
    "               'early_stopping_rounds': 10}\n",
    "\n",
    "best_params_bc = {'subsample': 0.7, \n",
    "                  'n_estimators': 1000,\n",
    "                  'min_child_weight': 3, \n",
    "                  'max_depth': 7, \n",
    "                  'learning_rate': 0.05, \n",
    "                  'gamma': 0.5, \n",
    "                  'colsample_bytree': 0.5,\n",
    "                  'objective': 'reg:absoluteerror',\n",
    "                  'early_stopping_rounds': 10}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train/Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_a, X_test_a, y_train_a, y_test_a = train_test_split(X_a, y_a, test_size=0.2, random_state=42)\n",
    "X_train_b, X_test_b, y_train_b, y_test_b = train_test_split(X_b, y_b, test_size=0.2, random_state=42)\n",
    "X_train_c, X_test_c, y_train_c, y_test_c = train_test_split(X_c, y_c, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Location A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Location A\n",
    "\n",
    "# Create an XGBoostRegressor with some default hyperparameters\n",
    "reg_A = xgb.XGBRegressor(**best_params_a)\n",
    "\n",
    "# Fit the model on the training data\n",
    "reg_A.fit(X_train_a, y_train_a,\n",
    "        eval_set = [(X_train_a, y_train_a), (X_test_a, y_test_a)],\n",
    "        verbose=100)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred_a = reg_A.predict(X_test_a)\n",
    "\n",
    "y_pred_a = np.clip(y_pred_a, a_min=0, a_max=None)\n",
    "\n",
    "# Calculate the Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test_a, y_pred_a)\n",
    "\n",
    "print(f\"Mean Absolute Error: {mae}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Location B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Location B\n",
    "\n",
    "# Create an XGBoostRegressor with some default hyperparameters\n",
    "reg_B = xgb.XGBRegressor(**best_params_bc)\n",
    "\n",
    "# Fit the model on the training data\n",
    "reg_B.fit(X_train_b, y_train_b,\n",
    "        eval_set = [(X_train_b, y_train_b), (X_test_b, y_test_b)],\n",
    "        verbose=100)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred_b = reg_B.predict(X_test_b)\n",
    "\n",
    "y_pred_b = np.clip(y_pred_b, a_min=0, a_max=None)\n",
    "\n",
    "# Calculate the Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test_b, y_pred_b)\n",
    "\n",
    "print(f\"Mean Absolute Error: {mae}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Location C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Location C\n",
    "\n",
    "# Create an XGBoostRegressor with some default hyperparameters\n",
    "reg_C = xgb.XGBRegressor(**best_params_bc)\n",
    "\n",
    "# Fit the model on the training data\n",
    "reg_C.fit(X_train_c, y_train_c,\n",
    "        eval_set = [(X_train_c, y_train_c), (X_test_c, y_test_c)],\n",
    "        verbose=100)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred_c = reg_C.predict(X_test_c)\n",
    "\n",
    "y_pred_c = np.clip(y_pred_c, a_min=0, a_max=None)\n",
    "\n",
    "# Calculate the Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test_c, y_pred_c)\n",
    "\n",
    "print(f\"Mean Absolute Error: {mae}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi_a = pd.DataFrame(data=reg_A.feature_importances_,\n",
    "             index=reg_A.feature_names_in_,\n",
    "             columns=[\"importance\"])\n",
    "fi_a.sort_values(\"importance\", ascending=False).head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi_b = pd.DataFrame(data=reg_B.feature_importances_,\n",
    "             index=reg_B.feature_names_in_,\n",
    "             columns=[\"importance\"])\n",
    "fi_b.sort_values(\"importance\", ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi_c = pd.DataFrame(data=reg_C.feature_importances_,\n",
    "             index=reg_C.feature_names_in_,\n",
    "             columns=[\"importance\"])\n",
    "fi_c.sort_values(\"importance\", ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizing the validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_a.plot()\n",
    "X_test_a[\"prediction\"] = y_pred_a\n",
    "X_test_a[\"prediction\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_b.plot()\n",
    "X_test_b[\"prediction\"] = y_pred_b\n",
    "X_test_b[\"prediction\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_c.plot()\n",
    "X_test_c[\"prediction\"] = y_pred_c\n",
    "X_test_c[\"prediction\"].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using the weather forecast part of the training data as a dummy unseen test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = X_train_estimated_a[FEATURES]\n",
    "df[\"prediction\"] = reg_A.predict(X_train_estimated_a[FEATURES])\n",
    "\n",
    "df = pd.merge(df, targets_a, left_index=True, right_index=True)\n",
    "\n",
    "df[\"error\"] = np.abs(df[\"pv_measurement\"] - df[\"prediction\"])\n",
    "display(df[\"error\"].sort_values(ascending=False).head())\n",
    "\n",
    "# Calculate the Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(df[\"pv_measurement\"], df[\"prediction\"])\n",
    "\n",
    "print(f\"Mean Absolute Error: {mae}\")\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "last_1000_values_df = df.tail(1000)\n",
    "\n",
    "mae_last = mean_absolute_error(last_1000_values_df[\"pv_measurement\"], last_1000_values_df[\"prediction\"])\n",
    "print(\"MAE for the last 1000 values:\", mae_last)\n",
    "\n",
    "df[\"pv_measurement\"].plot()\n",
    "df[\"prediction\"].plot() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = X_train_estimated_b[FEATURES]\n",
    "df[\"prediction\"] = reg_B.predict(X_train_estimated_b[FEATURES])\n",
    "\n",
    "df = pd.merge(df, targets_b, left_index=True, right_index=True)\n",
    "\n",
    "df[\"error\"] = np.abs(df[\"pv_measurement\"] - df[\"prediction\"])\n",
    "display(df[\"error\"].sort_values(ascending=False).head())\n",
    "\n",
    "# Calculate the Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(df[\"pv_measurement\"], df[\"prediction\"])\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "last_1000_values_df = df.tail(1000)\n",
    "\n",
    "print(f\"Mean Absolute Error: {mae}\")\n",
    "\n",
    "mae_last = mean_absolute_error(last_1000_values_df[\"pv_measurement\"], last_1000_values_df[\"prediction\"])\n",
    "print(\"MAE for the last 1000 values:\", mae_last)\n",
    "\n",
    "df[\"pv_measurement\"].plot()\n",
    "df[\"prediction\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = X_train_estimated_c[FEATURES]\n",
    "df[\"prediction\"] = reg_C.predict(X_train_estimated_c[FEATURES])\n",
    "\n",
    "df = pd.merge(df, targets_c, left_index=True, right_index=True)\n",
    "\n",
    "df[\"error\"] = np.abs(df[\"pv_measurement\"] - df[\"prediction\"])\n",
    "display(df[\"error\"].sort_values(ascending=False).head())\n",
    "\n",
    "# Calculate the Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(df[\"pv_measurement\"], df[\"prediction\"])\n",
    "print(f\"Mean Absolute Error: {mae}\")\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "last_1000_values_df = df.tail(1000)\n",
    "\n",
    "mae_last = mean_absolute_error(last_1000_values_df[\"pv_measurement\"], last_1000_values_df[\"prediction\"])\n",
    "print(\"MAE for the last 1000 values:\", mae_last)\n",
    "\n",
    "df[\"pv_measurement\"].plot()\n",
    "df[\"prediction\"].plot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting On The Actual Kaggle Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Location A\n",
    "X_test_estimated_a = X_test_estimated_a[FEATURES]\n",
    "A_pred = reg_A.predict(X_test_estimated_a)\n",
    "A_pred_hourly = []\n",
    "\n",
    "# just taking the value every whole hour\n",
    "for i in range(0, len(A_pred), 4):\n",
    "    A_pred_hourly.append(A_pred[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Location B\n",
    "X_test_estimated_b = X_test_estimated_b[FEATURES]\n",
    "B_pred = reg_B.predict(X_test_estimated_b)\n",
    "B_pred_hourly = []\n",
    "\n",
    "# just taking the value every whole hour\n",
    "for i in range(0, len(B_pred), 4):\n",
    "    B_pred_hourly.append(B_pred[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "### Location C\n",
    "X_test_estimated_c = X_test_estimated_c[FEATURES]\n",
    "C_pred = reg_C.predict(X_test_estimated_c)\n",
    "C_pred_hourly = []\n",
    "\n",
    "# just taking the value every whole hour\n",
    "for i in range(0, len(C_pred), 4):\n",
    "    C_pred_hourly.append(C_pred[i])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizing how the model predicts on the actual test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = X_test_estimated_a.copy()\n",
    "df[\"prediction\"] = reg_A.predict(X_test_estimated_a[FEATURES])\n",
    "\n",
    "start = \"05-2023\"\n",
    "end = \"08-2023\"\n",
    "feature = \"direct_rad:W\"\n",
    "\n",
    "plot_ts1([df[\"prediction\"]], [df], start, end, feature, shareX=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Storing the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.concatenate([A_pred_hourly, B_pred_hourly, C_pred_hourly])\n",
    "# remove negative and small positive predictions\n",
    "predictions = np.where(predictions < 0.05, 0, predictions)\n",
    "ids = range(len(predictions))\n",
    "df = pd.DataFrame({\"id\": ids, \"prediction\": predictions})\n",
    "df.to_csv(\"xgboost.csv\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoGluon"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model that gave us the best results was the AutoML model AutoGluon, which combines a bunch of traditional tree-based algorithms, in addition to neural networks and clustering algorithms. We have tried many different combinations of all the things we mentioned under Data Preprocessing, Feature Engineering and Model Training. We will provide a brief overview in text, and also some code for each location."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly to the XGBoost model, we used some functions to plot different features and the target value up against each other. See \"Helper functions.\" We also used the remove_constant_values() functions to remove rows where the target variable remained constant for different user specified thresholds, while also dropping NaN values.\n",
    "\n",
    "We also tried normalizing all the X features, but that led to worse results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ts(y: pd.DataFrame, x:pd.DataFrame, start, end, feature, shareX: bool):\n",
    "    \"\"\"\n",
    "    Plots all the y arrays, then all the x arrays.\n",
    "    \"\"\"\n",
    "    fig, axs = plt.subplots(len(x)+len(y), 1, figsize=(15,10), sharex=shareX)\n",
    "    i = 0\n",
    "    for df in y:\n",
    "        df[(df.index >= start) & (df.index <= end)].resample(\"H\").mean().plot(ax=axs[i])\n",
    "        i += 1\n",
    "    \n",
    "    for df in x:\n",
    "        df[(df.index >= start) & (df.index <= end)].resample(\"H\").mean()[feature].plot(ax=axs[i], label=feature, color=\"red\")\n",
    "        axs[i].legend()\n",
    "        i += 1\n",
    "    \n",
    "            \n",
    "def plot_ts1(y: pd.DataFrame, x:pd.DataFrame, start, end, feature, shareX: bool):\n",
    "    \"\"\"\n",
    "    Plots the y and x values directly under each other for each location\n",
    "    \"\"\"\n",
    "    \n",
    "    if len(x) != len(y):\n",
    "        print(\"Error: arrays 'y' and 'x' are different lengths. Please provide equal sized arrays.\")\n",
    "    else:\n",
    "        fig, axs = plt.subplots(len(x)+len(y), 1, figsize=(15,10), sharex=shareX)\n",
    "        i = 0\n",
    "        for df_y, df_x in zip(y, x):\n",
    "                df_y[(df_y.index >= start) & (df_y.index <= end)].resample(\"H\").mean().plot(ax=axs[i])\n",
    "                i += 1\n",
    "                df_x[(df_x.index >= start) & (df_x.index <= end)].resample(\"H\").mean()[feature].plot(ax=axs[i], label=feature, color=\"red\")\n",
    "                axs[i].legend()\n",
    "                i += 1\n",
    "  \n",
    "\n",
    "def remove_constant_values(df, column_name, threshold):\n",
    "    \n",
    "    new_df = df.copy()\n",
    "\n",
    "    # Find the consecutive constant rows\n",
    "    consecutive_constants = new_df.groupby((new_df[column_name] != new_df[column_name].shift()).cumsum()).filter(lambda x: len(x) > threshold)\n",
    "\n",
    "    # Filter out the consecutive constant rows from the original DataFrame\n",
    "    filtered_df = new_df[~new_df.index.isin(consecutive_constants.index)]\n",
    "    \n",
    "    return filtered_df\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have tried the following. Please see the example code for Location A:\n",
    "- adding time based features such as hour, day, month etc.\n",
    "- encoding those features as sine and cosine functions.\n",
    "- taking the mean of the 15 min interval features of each hourly period and using that as the hourly value.\n",
    "- marking wrong type features as correct type, eg. snow_drift:idx and other index features as \"category\" or \"int\" instead of float.\n",
    "- for each whole hour datapoint such as 15:00, append the 15:15, 15:30, and 15:45 values to that datapoint.\n",
    "- dropping various features based on either feature importance, intution, or lots of missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We experimented with:\n",
    "- Using only observed weather for training and validation\n",
    "- Using all estimated weather as validation set\n",
    "- Using some estimated weather in training, some in validation.\n",
    "- Various splits for what part of estimated weather we used in validation set.\n",
    "    Either split in at a given date, or sample random datapoints. When using random sample - we tried different percentages for how much of the estimated weather to use in validation, and also different random seeds.\n",
    "- We tried different presets in AutoGluon. For location A and B 'best quality' performed best. But for C our best model is still with no preset, ie. 'medium' quality."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We used autogluons leaderboard function to see which single model or ensemble model performed best.\n",
    "- We also used the feature importance function to see how important different features were, and removing the ones with negative score.\n",
    "- We plotted the models predicitons against the ground truth and also calculated the MAE for a local test set before submitting to Kaggle.\n",
    "- Calculated the biggest errors on local test set to possibly identify a pattern on where the model was missing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the end, we experimented with a multitude of combinations of preprocessing, feature engineering, train/val splits and model parameters. The best result used minimum feature engineering, best quality model, and a random sample of estimated weather as validation set for location A. For B, we used the same as A except simply the 50% first datapoints of estimated weather as validation data. For C, we removed a majority of the features, medium model quality and used the 50% first datapoints of estiamted weather as validation data. Please note that all the preproccesing can be studied in the short notebook. The code here does not necessarily contain all the things we have described in the text, but is meant as an example of most of it."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example code for Location A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ts(y: pd.DataFrame, x:pd.DataFrame, start, end, feature, shareX: bool):\n",
    "    \"\"\"\n",
    "    Plots all the y arrays, then all the x arrays.\n",
    "    \"\"\"\n",
    "    fig, axs = plt.subplots(len(x)+len(y), 1, figsize=(15,10), sharex=shareX)\n",
    "    i = 0\n",
    "    for df in y:\n",
    "        df[(df.index >= start) & (df.index <= end)].resample(\"H\").mean().plot(ax=axs[i])\n",
    "        i += 1\n",
    "    \n",
    "    for df in x:\n",
    "        df[(df.index >= start) & (df.index <= end)].resample(\"H\").mean()[feature].plot(ax=axs[i], label=feature, color=\"red\")\n",
    "        axs[i].legend()\n",
    "        i += 1\n",
    "    \n",
    "            \n",
    "def plot_ts1(y: pd.DataFrame, x:pd.DataFrame, start, end, feature, shareX: bool):\n",
    "    \"\"\"\n",
    "    Plots the y and x values directly under each other for each location\n",
    "    \"\"\"\n",
    "    \n",
    "    if len(x) != len(y):\n",
    "        print(\"Error: arrays 'y' and 'x' are different lengths. Please provide equal sized arrays.\")\n",
    "    else:\n",
    "        fig, axs = plt.subplots(len(x)+len(y), 1, figsize=(15,10), sharex=shareX)\n",
    "        i = 0\n",
    "        for df_y, df_x in zip(y, x):\n",
    "                df_y[(df_y.index >= start) & (df_y.index <= end)].resample(\"H\").mean().plot(ax=axs[i])\n",
    "                i += 1\n",
    "                df_x[(df_x.index >= start) & (df_x.index <= end)].resample(\"H\").mean()[feature].plot(ax=axs[i], label=feature, color=\"red\")\n",
    "                axs[i].legend()\n",
    "                i += 1\n",
    "  \n",
    "\n",
    "def remove_constant_values(df, column_name, threshold):\n",
    "    \n",
    "    new_df = df.copy()\n",
    "\n",
    "    # Find the consecutive constant rows\n",
    "    consecutive_constants = new_df.groupby((new_df[column_name] != new_df[column_name].shift()).cumsum()).filter(lambda x: len(x) > threshold)\n",
    "\n",
    "    # Filter out the consecutive constant rows from the original DataFrame\n",
    "    filtered_df = new_df[~new_df.index.isin(consecutive_constants.index)]\n",
    "    \n",
    "    return filtered_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in files and indexing them on time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_a = TabularDataset('data/A/train_targets.parquet')\n",
    "targets_a = targets_a.set_index('time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_observed_a = TabularDataset('data/A/X_train_observed.parquet')\n",
    "X_train_observed_a = X_train_observed_a.set_index(\"date_forecast\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_estimated_a = TabularDataset('data/A/X_train_estimated.parquet')\n",
    "X_train_estimated_a = X_train_estimated_a.set_index(\"date_forecast\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_estimated_a = TabularDataset('data/A/X_test_estimated.parquet')\n",
    "X_test_estimated_a = X_test_estimated_a.set_index(\"date_forecast\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing rows where pv_measurment remains the same for more than 18 hours.\n",
    "targets_a = remove_constant_values(targets_a, \"pv_measurement\", 18).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Sin/cos stuff. performed worse than not doing it\n",
    "def encode(data, col, max_val):\n",
    "    data[col + '_sin'] = np.sin(2 * np.pi * data[col]/max_val)\n",
    "    data[col + '_cos'] = np.cos(2 * np.pi * data[col]/max_val)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(df):\n",
    "    new_df = df.copy()\n",
    "    new_df['hour'] = new_df.index.hour\n",
    "    # encode(new_df, 'hour', 24.0)\n",
    "    # new_df = new_df.drop(columns=['hour'])\n",
    "    \n",
    "    # new_df['dayofweek'] = new_df.index.dayofweek\n",
    "    # new_df['quarter'] = new_df.index.quarter\n",
    "    new_df['month'] = new_df.index.month\n",
    "    # encode(new_df, 'month', 12.0)\n",
    "    # new_df = new_df.drop(columns=['month'])\n",
    "    \n",
    "    # new_df['year'] = new_df.index.year\n",
    "    # new_df['dayofyear'] = new_df.index.dayofyear\n",
    "    # encode(new_df, 'dayofyear', 365.0)\n",
    "    # new_df = new_df.drop(columns=['dayofyear'])\n",
    "    # new_df['dayofmonth'] = new_df.index.day\n",
    "    # new_df['weekofyear'] = new_df.index.isocalendar().week.astype(int)\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Adding more time based features to the datasets\n",
    "X_train_observed_a = create_features(X_train_observed_a)\n",
    "\n",
    "X_train_estimated_a = create_features(X_train_estimated_a)\n",
    "\n",
    "X_test_estimated_a = create_features(X_test_estimated_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Generally got worse performance when using this function.\n",
    "def mark_correct_type(df):\n",
    "    df['snow_drift:idx'] = df['snow_drift:idx'].astype(\"category\")\n",
    "    df['snow_density:kgm3'] = df['snow_density:kgm3'].astype(\"float\")\n",
    "    df['precip_type_5min:idx'] = df['precip_type_5min:idx'].astype(\"category\")\n",
    "    df['dew_or_rime:idx'] = df['dew_or_rime:idx'].astype(\"category\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_observed_a = mark_correct_type(X_train_observed_a)\n",
    "\n",
    "# X_train_estimated_a = mark_correct_type(X_train_estimated_a)\n",
    "\n",
    "# X_test_estimated_a = mark_correct_type(X_test_estimated_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_15min_fts(df, columns):\n",
    "    for column in columns:\n",
    "        # df[column+'-15'] = df[column].shift(1)\n",
    "        df[column+'15'] = df[column].shift(-1)\n",
    "        df[column+'30'] = df[column].shift(-2)\n",
    "        df[column+'45'] = df[column].shift(-3)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Input columns you want to add 15 min features for here:\n",
    "columns = [ \n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train_observed_a = add_15min_fts(X_train_observed_a, columns=columns)\n",
    "\n",
    "X_train_estimated_a = add_15min_fts(X_train_estimated_a, columns=columns)\n",
    "\n",
    "X_test_estimated_a = add_15min_fts(X_test_estimated_a, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Using only observed weather for training\n",
    "# Join the y values into x-dataframes for training\n",
    "train_a = pd.merge(X_train_observed_a, targets_a, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Using estimated weather for validation and local testing\n",
    "# Join the y values into x-dataframes \n",
    "test_a = pd.merge(X_train_estimated_a, targets_a, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove 'date_calc' from test set and kaggle set\n",
    "test_a.drop(columns=['date_calc'], inplace=True)\n",
    "X_test_estimated_a.drop(columns=['date_calc'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of column names to drop\n",
    "columns_to_drop = [\n",
    "    # 'snow_density:kgm3',\n",
    "    'snow_drift:idx',\n",
    "    'elevation:m',                    \n",
    "\n",
    "    \n",
    "    # 'rain_water:kgm2',\n",
    "    # 'cloud_base_agl:m',\n",
    "    # 'air_density_2m:kgm3',\n",
    "    # 'is_in_shadow:idx',\n",
    "    # 'pressure_50m:hPa',\n",
    "    # 'visibility:m',\n",
    "    # 'wind_speed_w_1000hPa:ms',\n",
    "    # 'ceiling_height_agl:m',\n",
    "    # 'snow_melt_10min:mm',\n",
    "    # 't_1000hPa:K',\n",
    "    \n",
    "]\n",
    "\n",
    "# Drop the specified columns from the DataFrames\n",
    "train_a = train_a.drop(columns=columns_to_drop)\n",
    "\n",
    "test_a = test_a.drop(columns=columns_to_drop)\n",
    "\n",
    "X_test_estimated_a = X_test_estimated_a.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalize (unused)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# # Assuming 'pv_measurement' is the target variable\n",
    "# target_train = train_a['pv_measurement']\n",
    "# target_test = test_a['pv_measurement']\n",
    "\n",
    "# train_a = train_a.drop(columns=['pv_measurement'])\n",
    "# test_a = test_a.drop(columns=['pv_measurement'])\n",
    "\n",
    "# # Initialize the MinMaxScaler for features\n",
    "# scaler_tr = MinMaxScaler()\n",
    "# scaler_te = MinMaxScaler()\n",
    "# scaler_kg = MinMaxScaler()\n",
    "\n",
    "# # Fit and transform the scalers on the original data for features\n",
    "# norm_train = scaler_tr.fit_transform(train_a)\n",
    "# norm_test = scaler_te.fit_transform(test_a)\n",
    "# norm_kaggle = scaler_kg.fit_transform(X_test_estimated_a)\n",
    "\n",
    "# # Create new DataFrames with the normalized features\n",
    "# train_a = pd.DataFrame(norm_train, index=train_a.index, columns=train_a.columns)\n",
    "# test_a = pd.DataFrame(norm_test, index=test_a.index, columns=test_a.columns)\n",
    "# X_test_estimated_a = pd.DataFrame(norm_kaggle, index=X_test_estimated_a.index, columns=X_test_estimated_a.columns)\n",
    "\n",
    "# # Concatenate the target variable back to the DataFrame\n",
    "# train_a['pv_measurement'] = target_train\n",
    "# test_a['pv_measurement'] = target_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some different functions for making tha val/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(df):\n",
    "    midpoint = len(df)//2\n",
    "    front = df.iloc[:midpoint]\n",
    "    end = df.iloc[midpoint:]\n",
    "    return front, end\n",
    "\n",
    "def split1000(df):\n",
    "    front = df.iloc[:-1000]\n",
    "    end = df.iloc[-1000:]\n",
    "    return front, end\n",
    "\n",
    "def sample_days(df, testfrac=0.5):\n",
    "    # Extract unique dates from the datetime index as a list of date objects\n",
    "    unique_dates = np.unique(df.index.date)\n",
    "    \n",
    "    combined_dates = []\n",
    "    \n",
    "    # Iterate through the unique dates and add all hours for each date\n",
    "    for date in unique_dates:\n",
    "        hours_for_date = df[df.index.date == date].index\n",
    "        \n",
    "        ### Only where all 24 hours are present for a date:\n",
    "        if len(hours_for_date) == 24:\n",
    "            combined_dates.append(hours_for_date)\n",
    "    \n",
    "    one = pd.Series(combined_dates).sample(frac=testfrac, random_state=42)\n",
    "    two = pd.Series(combined_dates)[~pd.Series(combined_dates).isin(one)]\n",
    "    \n",
    "    #flatten the series and filter the dataframes on those series\n",
    "    test = df[df.index.isin(one.explode())]\n",
    "    val = df[df.index.isin(two.explode())]\n",
    "    \n",
    "    return val, test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_days_org(df, testfrac=0.6):\n",
    "    # Extract unique dates from the datetime index as a list of date objects\n",
    "    unique_dates = np.unique(df.index.date)\n",
    "    \n",
    "    combined_dates = []\n",
    "    \n",
    "    # Iterate through the unique dates and add all hours for each date\n",
    "    for date in unique_dates:\n",
    "        hours_for_date = df[df.index.date == date].index.time\n",
    "        \n",
    "        ## If you want all datapoints:\n",
    "        combined_dates.extend([pd.Timestamp(date) + pd.DateOffset(hours=hour.hour) for hour in hours_for_date])\n",
    "        \n",
    "        ### Only where all 24 hours are present for a date:\n",
    "        # if len(hours_for_date) == 24:\n",
    "            # combined_dates.extend([pd.Timestamp(date) + pd.DateOffset(hours=hour.hour) for hour in hours_for_date])\n",
    "    \n",
    "    one = pd.Series(combined_dates).sample(frac=testfrac, random_state=35)\n",
    "    two = pd.Series(combined_dates)[~pd.Series(combined_dates).isin(one)]\n",
    "    \n",
    "    test = df[df.index.isin(one)]\n",
    "    val = df[df.index.isin(two)]\n",
    "    \n",
    "    return val, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Throw in some estimated weather to training as validation set, and the rest for testing\n",
    "val_a, test_a = sample_days_org(test_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Ensure a strict separation of validation and test set\n",
    "def all_indices_different(df1, df2):\n",
    "    # Check if all indices are different\n",
    "    return df1.index.intersection(df2.index).empty\n",
    "\n",
    "all_indices_different(val_a, test_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(val_a.shape[0])\n",
    "print(test_a.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Location A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_a = TabularPredictor(label='pv_measurement', eval_metric='mean_absolute_error').fit(train_data=train_a,\n",
    "                                                                                            tuning_data=val_a, \n",
    "                                                                                            presets='best_quality',\n",
    "                                                                                            use_bag_holdout=True,\n",
    "                                                                                            # # num_bag_folds=5, \n",
    "                                                                                            # # num_bag_sets=1, \n",
    "                                                                                            # # num_stack_levels=3,\n",
    "                                                                                            # excluded_model_types=excluded_model_types.\n",
    "                                                                                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_a.leaderboard(test_a, silent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature importance, takes long time to run when using best quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "# predictor_a.feature_importance(test_a,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load different models below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictor_a = TabularPredictor.load('AutogluonModels/best_a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using the weather forecast part of the training data as a dummy unseen test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = test_a.copy()\n",
    "a_pred = predictor_a.predict(test_a)\n",
    "a_pred = np.where(a_pred < 0.05, 0, a_pred)\n",
    "df[\"prediction\"] = a_pred\n",
    "\n",
    "# org_data = scaler_te.inverse_transform(df)\n",
    "# df = pd.DataFrame(org_data, index=df.index, columns=df.columns)\n",
    "\n",
    "df[\"error\"] = np.abs(df[\"pv_measurement\"] - df[\"prediction\"])\n",
    "display(df[\"error\"].sort_values(ascending=False).head())\n",
    "\n",
    "# Calculate the Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(df[\"pv_measurement\"], df[\"prediction\"])\n",
    "\n",
    "print(f\"Mean Absolute Error: {mae}\")\n",
    "\n",
    "last_1000_values_df = df.tail(1000)\n",
    "\n",
    "mae_last = mean_absolute_error(last_1000_values_df[\"pv_measurement\"], last_1000_values_df[\"prediction\"])\n",
    "print(\"MAE for the last 1000 values:\", mae_last)\n",
    "\n",
    "\n",
    "df[\"pv_measurement\"].plot()\n",
    "df[\"prediction\"].plot() \n",
    "\n",
    "# display(df.sort_values('error', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation with error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c_test = df.corrwith(df['error'])\n",
    "# for index, value in c_test.items():\n",
    "#     c_test[index] = (value)\n",
    "    \n",
    "# print(c_test.sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing What Mistakes It Makes on tuning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = val_a.copy()\n",
    "a_pred = predictor_a.predict(val_a)\n",
    "a_pred = np.where(a_pred < 0.05, 0, a_pred)\n",
    "df[\"prediction\"] = a_pred\n",
    "\n",
    "\n",
    "df[\"error\"] = np.abs(df[\"pv_measurement\"] - df[\"prediction\"])\n",
    "display(df[\"error\"].sort_values(ascending=False).head())\n",
    "\n",
    "# Calculate the Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(df[\"pv_measurement\"], df[\"prediction\"])\n",
    "\n",
    "print(f\"Mean Absolute Error: {mae}\")\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "last_1000_values_df = df.tail(1000)\n",
    "\n",
    "mae_last = mean_absolute_error(last_1000_values_df[\"pv_measurement\"], last_1000_values_df[\"prediction\"])\n",
    "print(\"MAE for the last 1000 values:\", mae_last)\n",
    "\n",
    "df[\"pv_measurement\"].plot()\n",
    "df[\"prediction\"].plot() \n",
    "\n",
    "# display(df.sort_values('error', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting on the actual test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Location A\n",
    "A_pred = predictor_a.predict(X_test_estimated_a)\n",
    "A_pred_hourly = []\n",
    "\n",
    "# just taking the value every whole hour\n",
    "for i in range(0, len(A_pred), 4):\n",
    "    A_pred_hourly.append(A_pred[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing how the model predicts on the actual test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = X_test_estimated_a.copy()\n",
    "# df[\"prediction\"] = predictor_a.predict(X_test_estimated_a)\n",
    "\n",
    "# start = \"05-2023\"\n",
    "# end = \"08-2023\"\n",
    "# feature = \"direct_rad:W\"\n",
    "\n",
    "# plot_ts1([df[\"prediction\"]], [df], start, end, feature, shareX=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.array(A_pred_hourly)\n",
    "# remove negative and small positive predictions\n",
    "predictions = np.where(predictions < 0.05, 0, predictions)\n",
    "ids = range(len(predictions))\n",
    "df = pd.DataFrame({\"id\": ids, \"prediction\": predictions})\n",
    "# df.to_csv(\"saves/A/autogluon_A.csv\", index=False)\n",
    "\n",
    "import os\n",
    "\n",
    "directory = \"saves/A/\"\n",
    "base_filename = \"autogluon_A.csv\"\n",
    "\n",
    "# Find the next available number to append to the filename\n",
    "i = 1\n",
    "while True:\n",
    "    filename = os.path.join(directory, f\"{base_filename[:-4]}_{i}.csv\")\n",
    "    if not os.path.isfile(filename):\n",
    "        break\n",
    "    i += 1\n",
    "\n",
    "# Save the DataFrame to the new filename\n",
    "df.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example code for Location B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in files and indexing them on time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_b = TabularDataset('data/B/train_targets.parquet')\n",
    "targets_b = targets_b.set_index(\"time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_observed_b = TabularDataset('data/B/X_train_observed.parquet')\n",
    "X_train_observed_b = X_train_observed_b.set_index(\"date_forecast\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_estimated_b = TabularDataset('data/B/X_train_estimated.parquet')\n",
    "X_train_estimated_b = X_train_estimated_b.set_index(\"date_forecast\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_estimated_b = TabularDataset('data/B/X_test_estimated.parquet')\n",
    "X_test_estimated_b = X_test_estimated_b.set_index(\"date_forecast\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing rows where pv_measurment remains the same for more than 18 hours.\n",
    "targets_b = remove_constant_values(targets_b, \"pv_measurement\", 18).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(df):\n",
    "    new_df = df.copy()\n",
    "    new_df['hour'] = new_df.index.hour\n",
    "    new_df['dayofweek'] = new_df.index.dayofweek\n",
    "    new_df['quarter'] = new_df.index.quarter\n",
    "    # new_df['month'] = new_df.index.month\n",
    "    # # new_df['year'] = new_df.index.year\n",
    "    # # new_df['dayofyear'] = new_df.index.dayofyear\n",
    "    # # new_df['dayofmonth'] = new_df.index.day\n",
    "    new_df['weekofyear'] = new_df.index.isocalendar().week.astype(int)\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Adding more time based features to the datasets\n",
    "X_train_observed_b = create_features(X_train_observed_b)\n",
    "\n",
    "X_train_estimated_b = create_features(X_train_estimated_b)\n",
    "\n",
    "X_test_estimated_b = create_features(X_test_estimated_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mark_correct_type(df):\n",
    "    df['snow_drift:idx'] = df['snow_drift:idx'].astype(\"category\")\n",
    "    df['snow_density:kgm3'] = df['snow_density:kgm3'].astype(\"float\")\n",
    "    df['precip_type_5min:idx'] = df['precip_type_5min:idx'].astype(\"category\")\n",
    "    df['dew_or_rime:idx'] = df['dew_or_rime:idx'].astype(\"category\")\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_observed_b = mark_correct_type(X_train_observed_b)\n",
    "\n",
    "# X_train_estimated_b = mark_correct_type(X_train_estimated_b)\n",
    "\n",
    "# X_test_estimated_b = mark_correct_type(X_test_estimated_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_15min_fts(df, columns):\n",
    "    for column in columns:\n",
    "        df[column+'15'] = df[column].shift(-1)\n",
    "        df[column+'30'] = df[column].shift(-2)\n",
    "        df[column+'45'] = df[column].shift(-3)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    "#     'effective_cloud_cover:p',\n",
    "# 'total_cloud_cover:p',\n",
    "# 'wind_speed_u_10m:ms'\n",
    "]\n",
    "\n",
    "X_train_observed_b = add_15min_fts(X_train_observed_b, columns=columns)\n",
    "\n",
    "X_train_estimated_b = add_15min_fts(X_train_estimated_b, columns=columns)\n",
    "\n",
    "X_test_estimated_b = add_15min_fts(X_test_estimated_b, columns=columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Using only observed weather for training\n",
    "# Join the y values into x-dataframes for training\n",
    "train_b = pd.merge(X_train_observed_b, targets_b, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Using only observed weather for training\n",
    "# Join the y values into x-dataframes for training\n",
    "test_b = pd.merge(X_train_estimated_b, targets_b, left_index=True, right_index=True)\n",
    "\n",
    "# Remove 'date_calc' from test set and kaggle set\n",
    "test_b.drop(columns=['date_calc'], inplace=True)\n",
    "\n",
    "X_test_estimated_b.drop(columns=['date_calc'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of column names to drop\n",
    "columns_to_drop = [\n",
    "  'elevation:m', \n",
    "  'snow_drift:idx',\n",
    "  \n",
    "  # 'air_density_2m:kgm3',\n",
    "  # 'absolute_humidity_2m:gm3',\n",
    "  # 'ceiling_height_agl:m',\n",
    "  # 'dew_point_2m:K',\n",
    "  # 'wind_speed_w_1000hPa:ms',\n",
    "  # 'rain_water:kgm2',\n",
    "  # 'visibility:m',\n",
    "  # 'pressure_100m:hPa',\n",
    "    ]\n",
    "\n",
    "# Drop the specified columns from the DataFrames\n",
    "train_b = train_b.drop(columns=columns_to_drop)\n",
    "\n",
    "test_b = test_b.drop(columns=columns_to_drop)\n",
    "\n",
    "X_test_estimated_b = X_test_estimated_b.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(df):\n",
    "    midpoint = len(df)//2\n",
    "    front = df.iloc[:midpoint]\n",
    "    end = df.iloc[midpoint:]\n",
    "    return front, end\n",
    "\n",
    "def split1000(df):\n",
    "    midpoint = len(df)//2\n",
    "    front = df.iloc[:-1000]\n",
    "    end = df.iloc[-1000:]\n",
    "    return front, end\n",
    "\n",
    "def sample_days(df, testfrac=0.65):\n",
    "    # Extract unique dates from the datetime index as a list of date objects\n",
    "    unique_dates = np.unique(df.index.date)\n",
    "    \n",
    "    combined_dates = []\n",
    "    \n",
    "    # Iterate through the unique dates and add all hours for each date\n",
    "    for date in unique_dates:\n",
    "        hours_for_date = df[df.index.date == date].index.time\n",
    "        \n",
    "        ### If you want all datapoints:\n",
    "        combined_dates.extend([pd.Timestamp(date) + pd.DateOffset(hours=hour.hour) for hour in hours_for_date])\n",
    "        \n",
    "        ### Only where all 24 hours are present for a date:\n",
    "        # if len(hours_for_date) == 24:\n",
    "        #     combined_dates.extend([pd.Timestamp(date) + pd.DateOffset(hours=hour.hour) for hour in hours_for_date])\n",
    "    \n",
    "    one = pd.Series(combined_dates).sample(frac=testfrac, random_state=35)\n",
    "    two = pd.Series(combined_dates)[~pd.Series(combined_dates).isin(one)]\n",
    "    \n",
    "    test = df[df.index.isin(one)]\n",
    "    val = df[df.index.isin(two)]\n",
    "    \n",
    "    return val, test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Throw in some estimated weather to training as validation set, and the rest for testing\n",
    "val_b, test_b = split(test_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_b.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Location B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_b = TabularPredictor(label='pv_measurement', eval_metric='mean_absolute_error').fit(train_b,\n",
    "                                                                                            tuning_data=val_b, \n",
    "                                                                                            presets='best_quality',\n",
    "                                                                                            use_bag_holdout=True,\n",
    "                                                                                            # # num_bag_folds=5, \n",
    "                                                                                            # # num_bag_sets=1, \n",
    "                                                                                            # # num_stack_levels=3,\n",
    "                                                                                            # excluded_model_types=excluded_model_types\n",
    "                                                                                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_b.leaderboard(test_b, silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictor_b.feature_importance(test_b, num_shuffle_sets=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictor_b = TabularPredictor.load('AutogluonModels/best_b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using the weather forecast part of the training data as a dummy unseen test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = test_b.copy()\n",
    "b_pred = predictor_b.predict(test_b)\n",
    "b_pred = np.where(b_pred < 0.05, 0, b_pred)\n",
    "df[\"prediction\"] = b_pred\n",
    "\n",
    "# df = pd.merge(df, targets_a, left_index=True, right_index=True)\n",
    "\n",
    "df[\"error\"] = np.abs(df[\"pv_measurement\"] - df[\"prediction\"])\n",
    "display(df[\"error\"].sort_values(ascending=False).head())\n",
    "\n",
    "# Calculate the Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(df[\"pv_measurement\"], df[\"prediction\"])\n",
    "\n",
    "print(f\"Mean Absolute Error: {mae}\")\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "last_1000_values_df = df.tail(1000)\n",
    "\n",
    "mae_last = mean_absolute_error(last_1000_values_df[\"pv_measurement\"], last_1000_values_df[\"prediction\"])\n",
    "print(\"MAE for the last 1000 values:\", mae_last)\n",
    "\n",
    "df[\"pv_measurement\"].plot()\n",
    "df[\"prediction\"].plot() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How it does on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = val_b.copy()\n",
    "b_pred = predictor_b.predict(val_b)\n",
    "b_pred = np.where(b_pred < 0.05, 0, b_pred)\n",
    "df[\"prediction\"] = b_pred\n",
    "\n",
    "# df = pd.merge(df, targets_a, left_index=True, right_index=True)\n",
    "\n",
    "df[\"error\"] = np.abs(df[\"pv_measurement\"] - df[\"prediction\"])\n",
    "display(df[\"error\"].sort_values(ascending=False).head())\n",
    "\n",
    "# Calculate the Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(df[\"pv_measurement\"], df[\"prediction\"])\n",
    "\n",
    "print(f\"Mean Absolute Error: {mae}\")\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "last_1000_values_df = df.tail(1000)\n",
    "\n",
    "mae_last = mean_absolute_error(last_1000_values_df[\"pv_measurement\"], last_1000_values_df[\"prediction\"])\n",
    "print(\"MAE for the last 1000 values:\", mae_last)\n",
    "\n",
    "df[\"pv_measurement\"].plot()\n",
    "df[\"prediction\"].plot() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting on the actual test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Location B\n",
    "B_pred = predictor_b.predict(X_test_estimated_b)\n",
    "B_pred_hourly = []\n",
    "\n",
    "# just taking the value every whole hour\n",
    "for i in range(0, len(B_pred), 4):\n",
    "    B_pred_hourly.append(B_pred[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing how the model predicts on the actual test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = X_test_estimated_b.copy()\n",
    "# df[\"prediction\"] = predictor_b.predict(X_test_estimated_b)\n",
    "\n",
    "# start = \"05-2023\"\n",
    "# end = \"08-2023\"\n",
    "# feature = \"direct_rad:W\"\n",
    "\n",
    "# utils4.plot_ts1([df[\"prediction\"]], [df], start, end, feature, shareX=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.array(B_pred_hourly)\n",
    "# remove negative and small positive predictions\n",
    "predictions = np.where(predictions < 0.05, 0, predictions)\n",
    "ids = range(720, 720 + len(predictions))\n",
    "df = pd.DataFrame({\"id\": ids, \"prediction\": predictions})\n",
    "\n",
    "import os\n",
    "\n",
    "directory = \"saves/B/\"\n",
    "base_filename = \"autogluon_B.csv\"\n",
    "\n",
    "# Find the next available number to append to the filename\n",
    "i = 1\n",
    "while True:\n",
    "    filename = os.path.join(directory, f\"{base_filename[:-4]}_{i}.csv\")\n",
    "    if not os.path.isfile(filename):\n",
    "        break\n",
    "    i += 1\n",
    "\n",
    "# Save the DataFrame to the new filename\n",
    "df.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example code for Location C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in files and indexing them on time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "targets_c = TabularDataset('data/C/train_targets.parquet')\n",
    "targets_c = targets_c.set_index(\"time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_observed_c = TabularDataset('data/C/X_train_observed.parquet')\n",
    "X_train_observed_c = X_train_observed_c.set_index(\"date_forecast\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_estimated_c = TabularDataset('data/C/X_train_estimated.parquet')\n",
    "X_train_estimated_c = X_train_estimated_c.set_index(\"date_forecast\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_estimated_c = TabularDataset('data/C/X_test_estimated.parquet')\n",
    "X_test_estimated_c = X_test_estimated_c.set_index(\"date_forecast\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing rows where pv_measurment remains the same for more than 18 hours.\n",
    "targets_c = remove_constant_values(targets_c, \"pv_measurement\", 18).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(df):\n",
    "    new_df = df.copy()\n",
    "    # new_df['hour'] = new_df.index.hour\n",
    "    # new_df['dayofweek'] = new_df.index.dayofweek\n",
    "    # new_df['quarter'] = new_df.index.quarter\n",
    "    # new_df['month'] = new_df.index.month\n",
    "    # new_df['year'] = new_df.index.year\n",
    "    new_df['dayofyear'] = new_df.index.dayofyear\n",
    "    # new_df['dayofmonth'] = new_df.index.day\n",
    "    new_df['weekofyear'] = new_df.index.isocalendar().week.astype(int)\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Adding more time based features to the datasets\n",
    "X_train_observed_c = create_features(X_train_observed_c)\n",
    "\n",
    "X_train_estimated_c = create_features(X_train_estimated_c)\n",
    "\n",
    "X_test_estimated_c = create_features(X_test_estimated_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_estimated_c.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mark_correct_type(df):\n",
    "    df['snow_drift:idx'] = df['snow_drift:idx'].astype(\"category\")\n",
    "    df['snow_density:kgm3'] = df['snow_density:kgm3'].astype(\"float\")\n",
    "    df['precip_type_5min:idx'] = df['precip_type_5min:idx'].astype(\"category\")\n",
    "    df['dew_or_rime:idx'] = df['dew_or_rime:idx'].astype(\"category\")\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_observed_c= mark_correct_type(X_train_observed_c)\n",
    "\n",
    "# X_train_estimated_c = mark_correct_type(X_train_estimated_c)\n",
    "\n",
    "# X_test_estimated_c = mark_correct_type(X_test_estimated_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_15min_fts(df, columns):\n",
    "    for column in columns:\n",
    "        df[column+'15'] = df[column].shift(-1)\n",
    "        df[column+'30'] = df[column].shift(-2)\n",
    "        df[column+'45'] = df[column].shift(-3)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = []\n",
    "\n",
    "X_train_observed_c = add_15min_fts(X_train_observed_c, columns=columns)\n",
    "\n",
    "X_train_estimated_c = add_15min_fts(X_train_estimated_c, columns=columns)\n",
    "\n",
    "X_test_estimated_c = add_15min_fts(X_test_estimated_c, columns=columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Using only observed weather for training\n",
    "# Join the y values into x-dataframes for training\n",
    "train_c = pd.merge(X_train_observed_c, targets_c, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Using only observed weather for training\n",
    "# Join the y values into x-dataframes for training\n",
    "test_c = pd.merge(X_train_estimated_c, targets_c, left_index=True, right_index=True)\n",
    "\n",
    "# Remove 'date_calc' from test set and kaggle set\n",
    "test_c.drop(columns=['date_calc'], inplace=True)\n",
    "X_test_estimated_c.drop(columns=['date_calc'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of column names to drop\n",
    "columns_to_drop = [\n",
    "\n",
    " 'air_density_2m:kgm3', \n",
    " 'ceiling_height_agl:m', \n",
    " 'cloud_base_agl:m', \n",
    " 'dew_or_rime:idx',\n",
    " 'effective_cloud_cover:p',\n",
    " 'elevation:m',\n",
    " 'fresh_snow_1h:cm', \n",
    " 'fresh_snow_24h:cm', \n",
    " 'is_day:idx',\n",
    " 'is_in_shadow:idx',\n",
    " 'msl_pressure:hPa',\n",
    " 'precip_5min:mm', \n",
    " 'precip_type_5min:idx',\n",
    " 'pressure_100m:hPa',\n",
    " 'pressure_50m:hPa', \n",
    " 'prob_rime:p', \n",
    " 'rain_water:kgm2', \n",
    " 'relative_humidity_1000hPa:p', \n",
    " 'sfc_pressure:hPa',\n",
    " 'snow_density:kgm3',\n",
    " 'snow_drift:idx', \n",
    " 'snow_water:kgm2',\n",
    " 'sun_azimuth:d',\n",
    " 'super_cooled_liquid_water:kgm2',\n",
    " 't_1000hPa:K', \n",
    " 'total_cloud_cover:p',\n",
    " 'visibility:m', \n",
    " 'wind_speed_10m:ms',\n",
    " 'wind_speed_u_10m:ms',\n",
    " 'wind_speed_v_10m:ms'\n",
    "\n",
    "\n",
    "]\n",
    "\n",
    "# Drop the specified columns from the DataFrames\n",
    "train_c = train_c.drop(columns=columns_to_drop)\n",
    "\n",
    "test_c = test_c.drop(columns=columns_to_drop)\n",
    "\n",
    "X_test_estimated_c = X_test_estimated_c.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(df):\n",
    "    midpoint = len(df)//2\n",
    "    front = df.iloc[:midpoint]\n",
    "    end = df.iloc[midpoint:]\n",
    "    return front, end\n",
    "\n",
    "def split1000(df):\n",
    "    midpoint = len(df)//2\n",
    "    front = df.iloc[:-1000]\n",
    "    end = df.iloc[-1000:]\n",
    "    return front, end\n",
    "\n",
    "def sample_days(df, testfrac=0.55):\n",
    "    # Extract unique dates from the datetime index as a list of date objects\n",
    "    unique_dates = np.unique(df.index.date)\n",
    "    \n",
    "    combined_dates = []\n",
    "    \n",
    "    # Iterate through the unique dates and add all hours for each date\n",
    "    for date in unique_dates:\n",
    "        hours_for_date = df[df.index.date == date].index.time\n",
    "        \n",
    "        ### If you want all datapoints:\n",
    "        # combined_dates.extend([pd.Timestamp(date) + pd.DateOffset(hours=hour.hour) for hour in hours_for_date])\n",
    "        \n",
    "        ### Only where all 24 hours are present for a date:\n",
    "        if len(hours_for_date) == 24:\n",
    "            combined_dates.extend([pd.Timestamp(date) + pd.DateOffset(hours=hour.hour) for hour in hours_for_date])\n",
    "    \n",
    "    one = pd.Series(combined_dates).sample(frac=testfrac, random_state=35)\n",
    "    two = pd.Series(combined_dates)[~pd.Series(combined_dates).isin(one)]\n",
    "    \n",
    "    test = df[df.index.isin(one)]\n",
    "    val = df[df.index.isin(two)]\n",
    "    \n",
    "    return val, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Throw in some estimated weather to training as validation set, and the rest for testing\n",
    "val_c, test_c = split(test_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Location C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_c = TabularPredictor(label='pv_measurement', eval_metric='mean_absolute_error').fit(train_c,\n",
    "                                                                                            tuning_data=val_c, \n",
    "                                                                                            # presets='best_quality',\n",
    "                                                                                            # use_bag_holdout=True,\n",
    "                                                                                            # # num_bag_folds=5, \n",
    "                                                                                            # # num_bag_sets=1, \n",
    "                                                                                            # # num_stack_levels=3,\n",
    "                                                                                            # excluded_model_types=excluded_model_types\n",
    "                                                                                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictor_c = TabularPredictor.load('AutogluonModels/best_c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_c.leaderboard(test_c, silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_c.feature_importance(test_c, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using the weather forecast part of the training data as a dummy unseen test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = test_c.copy()\n",
    "c_pred = predictor_c.predict(test_c)\n",
    "c_pred = np.where(c_pred < 0.05, 0, c_pred)\n",
    "df[\"prediction\"] = c_pred\n",
    "\n",
    "# df = pd.merge(df, targets_a, left_index=True, right_index=True)\n",
    "\n",
    "df[\"error\"] = np.abs(df[\"pv_measurement\"] - df[\"prediction\"])\n",
    "display(df[\"error\"].sort_values(ascending=False).head())\n",
    "\n",
    "# Calculate the Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(df[\"pv_measurement\"], df[\"prediction\"])\n",
    "\n",
    "print(f\"Mean Absolute Error: {mae}\")\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "last_1000_values_df = df.tail(1000)\n",
    "\n",
    "mae_last = mean_absolute_error(last_1000_values_df[\"pv_measurement\"], last_1000_values_df[\"prediction\"])\n",
    "print(\"MAE for the last 1000 values:\", mae_last)\n",
    "\n",
    "df[\"pv_measurement\"].plot()\n",
    "df[\"prediction\"].plot() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting on the actual test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Location C\n",
    "C_pred = predictor_c.predict(X_test_estimated_c)\n",
    "C_pred_hourly = []\n",
    "\n",
    "# just taking the value every whole hour\n",
    "for i in range(0, len(C_pred), 4):\n",
    "    C_pred_hourly.append(C_pred[i])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing how the model predicts on the actual test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = X_test_estimated_c.copy()\n",
    "df[\"prediction\"] = predictor_c.predict(X_test_estimated_c)\n",
    "\n",
    "start = \"05-2023\"\n",
    "end = \"08-2023\"\n",
    "feature = \"direct_rad:W\"\n",
    "\n",
    "plot_ts1([df[\"prediction\"]], [df], start, end, feature, shareX=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.array(C_pred_hourly)\n",
    "# remove negative and small positive predictions\n",
    "predictions = np.where(predictions < 0.05, 0, predictions)\n",
    "ids = range(1440, 1440 + len(predictions))\n",
    "df = pd.DataFrame({\"id\": ids, \"prediction\": predictions})\n",
    "\n",
    "import os\n",
    "\n",
    "directory = \"saves/C/\"\n",
    "base_filename = \"autogluon_C.csv\"\n",
    "\n",
    "# Find the next available number to append to the filename\n",
    "i = 1\n",
    "while True:\n",
    "    filename = os.path.join(directory, f\"{base_filename[:-4]}_{i}.csv\")\n",
    "    if not os.path.isfile(filename):\n",
    "        break\n",
    "    i += 1\n",
    "\n",
    "# Save the DataFrame to the new filename\n",
    "df.to_csv(filename, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
